{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from typing import Tuple, Dict, Any, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.data.clean import clean\n",
    "from src.data.wrangle import wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64574ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_data = pd.read_csv('FACE/neuropsy_bp.csv', sep=';', low_memory=False)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "df_cleaned = clean(raw_data)\n",
    "df_cleaned.to_csv('FACE/neuropsy_bp_cleaned.csv', index=False)\n",
    "\n",
    "\n",
    "df_wrangled, params, wr = wrangle(df_cleaned, conversion_threshold=0.80, cardinality_threshold=10, scale_numeric=True)\n",
    "df_wrangled.to_csv('FACE/neuropsy_bp_wrangled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2800a0",
   "metadata": {},
   "source": [
    "# Visulaising the data\n",
    "Perform correlation analysis on the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55687a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation matrix, visualize it as a heatmap, and identify strong correlations.\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_wrangled.corr(method='pearson')\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(20, 20))  # Adjust figure size as needed\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5614ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for the first N_COLS columns\n",
    "N_COLS = 60\n",
    "correlation_matrix = df_wrangled[df_wrangled.columns[:N_COLS]].corr(method='pearson')\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(20, 20))  # Adjust figure size as needed\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34bc475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partial = df_wrangled[df_wrangled.columns[:N_COLS]]\n",
    "df_partial.describe()\n",
    "\n",
    "df_partial.to_csv(f\"FACE/neuropsy_bp_partial_n_cols_{N_COLS}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa337b",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "1. Split into numeric and categorical features\n",
    "2. Create PreprocessedData containing TabularDataset\n",
    "    - 2.1. Preprocess data / or not if data is already preprocessed (in our case - yes)\n",
    "    - 2.2. Examine torch dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a44d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import split_numerical_categorical, reconstruct_dataframe\n",
    "from src.data.dataset import TabularDataset, preprocess_data, PreprocessedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mat, cat_mat, mapping = split_numerical_categorical(df_partial, cardinality_threshold=7)\n",
    "\n",
    "num_mat = num_mat.astype(np.float32)\n",
    "cat_mat = cat_mat.astype(np.int64)\n",
    "\n",
    "df_partial_converted = reconstruct_dataframe(num_mat, cat_mat, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434091dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data(num_mat=num_mat, cat_mat=cat_mat, y=None, mapping=mapping,\n",
    "    test_size=0.25, transform=False, scaling_strategy=None, cat_encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape: \", data.X_train.shape)\n",
    "print(\"X_test shape: \", data.X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import split_numerical_categorical, reconstruct_dataframe\n",
    "from src.data.dataset import TabularDataset, preprocess_data, PreprocessedData\n",
    "\n",
    "df_wrangled = pd.read_csv('FACE/neuropsy_bp_partial_n_cols_60.csv')\n",
    "num_mat, cat_mat, mapping = split_numerical_categorical(df_wrangled, cardinality_threshold=7)\n",
    "\n",
    "num_mat = num_mat.astype(np.float32)\n",
    "cat_mat = cat_mat.astype(np.int64)\n",
    "\n",
    "preprocessed_data = preprocess_data(num_mat=num_mat, cat_mat=cat_mat, y=None, mapping=mapping,\n",
    "    test_size=0.25, transform=False, scaling_strategy=None, cat_encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff38908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e547b8e7",
   "metadata": {},
   "source": [
    "# Generate new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee89c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from src.trainer.vae_trainer import VAETrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817973a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.category_embeddings.weight.shape=torch.Size([209, 4])\n",
      "Model configuration:\n",
      "- Latent dimension: 4\n",
      "- Number of numerical features: 5\n",
      "- Number of categorical features: 55\n",
      "- Categories: [4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "checkpoint = \"ckpt/model.pt\"\n",
    "num_samples = 128\n",
    "\n",
    "model, model_config = VAETrainer.load_model(checkpoint, device=device)\n",
    "\n",
    "d_token = model_config['model_params']['d_token']\n",
    "categories = model_config['model_params']['categories']\n",
    "d_numerical = model_config['model_params']['d_numerical']\n",
    "print(f\"Model configuration:\")\n",
    "print(f\"- Latent dimension: {d_token}\")\n",
    "print(f\"- Number of numerical features: {d_numerical}\")\n",
    "print(f\"- Number of categorical features: {len(categories)}\")\n",
    "print(f\"- Categories: {categories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bca9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num, cat = model.sample(num_samples=128, current_device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafb905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
